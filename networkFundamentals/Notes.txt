


Data plane - local per router function. Determinse how data arriving on router input port is forwarded to router output port by examining the headers.
              This has look up table which is populated by control plane. This just looks the look up table to send to the next destination.

              - packet buffering, packet scheduling, Header modification and forwarding.
              - If packet info not in forwaring table, It communicates vertically to control plane

Control plane - Network wide logic determines how data is routed among routers along end to end path from source to destination.
                  This has 2 approaches
                   a. Traditional routing algorithms implemeneted in routers.
                   b. Software Defined Network (SDN) implemented in remote servers.

Management plane - Network adming configures and monitor switch through this plane.

Traditional routing algorithms.

1. link state algorithm - Djkstra's shorted path algorithm
    - This alogorithm runs based on the link cost. Each node in the network will advertise its link costs to every other node in the network.
      So, At the end it will have global link state (or Graph) snapshots which shows the link cost between every node to every other node.
      Once we have this link state in all the routers, Then Djstra's algorithm will be run to find out shortest path between any 2 nodes.
      Then this data is feeded to routing look up table in data plane.

2. Distance vector algorithm - Bellman ford's algorithm  - Not so popular and less used.
    -  In this algo, Every node advertises only to its adjacent node about the best path to reach other nodes from itself.
        example : A --- B --- C
                        |     |
                        D --- E
          In this example, B advertises to A that best path to reach to E is D if link cost from B-D-E is less compared to cost B-C-E
        This way it calculates distance and advertise it to other nodes.
        This algorithm is not widely used not because of some convergence problems.

These traditional algorithms are not suitable for large networks on the internet. These are mostly suitable for LAN or small autonomus networks.


**** Routing protocals on the internet *****
 Autonomous Systems - Small network or domain managed by only 1 admin.

There are 2 ways of communications here
1. - Intra Autonomous - communication that happens within the AS
2. - Inter Autonomous or domain - Communicatinon that happens between AS. Example 1 ISP to another ISP. This is how internet is connected with network of networks.


In order to have links over larger networks, There are 2 ways how routing tables are populated.

1. Intra domain communcation - This is done via link state algorithm
2. Inter domain communication - This is done via BGP (Border Gateway Protocol)

Border Gateway protocols are of 2 types.
1 - iBGP - Intra BGP - Protocal that runs within the autonomus systems to advertise external autonoums system path to every node in the AS.
2. - eBGP - external BGP - Protocal that runs thru gateway router of one AS to other As to advertise its path to gateway router in other AS.
            This advertisement is done via subnets.
            example : AS1 can have subnet of 198.18.*.* and AS2 can have subnet of 198.21.*.*
            Now AS1 can advertise AS2 with its gateway router that it can be reached via subnet 198.18.*.*.
            By this AS2 will learn that all the packets which have destination ip staring with 198.18 will have to go to AS1 via its gateway router.

Internet is scalabe because of this aggregation of networks with subnets.

Now Routing table of AS2 has entries like
AS1 - Gatway router of AS1   ----- This is found out with eBGP
Gateway router of AS1 - can be reached via some internal router say D  ---- This is found out linkstate algorithm


********************************************************************************************************************

Transport layer protocols.

UDP - connectionless, non reliable, out of order packets, no congestion/flow control, Fast
      If application needs packets in order it has to handle by its own.
      Useful in streaming

TCP - Connection oriented(Three way handshake), Reliable, In order packets, Less faster comapred to UDP, cumulative ack,
      Flow control and congestion control is handled in tcp layer itself.
      Retransmission of packets based on ACK.
      Works based on slinding window - Maximum n packets can be sent over the network for which ack is not received yet. Once ACK is received 
      for x bytes window will be moved to x bytes further and it can send x bytes more.

Flow control - If sender is sending packets faster than what receiver can take then packets will be lost at the receiver end as application is slow to process requests.
               Receiver end socket has buffer up to which it can hold the data, Once the buffer is full packets will be dropped and it causes retranmission of packets.
               To solve this TCP can send receiver window size, Based on this sender restricts to send only that many bytes and this avoids retranmissions.

Congestion control - Too much of traffic arriving from different source and converged at particular node causing congestion.

********************************************************************************************************************

SDN (SOftware Defined Network)

Data plane functions is implemented in each of the router but control plane functions are implemented at the remote centralized server.
remote server make decisions on path and communicated to each router and forwarding tables are populated.

CA - control plane agent in each router talking to remote server.

SDN is desinged to handle east - west traffic, changing network in Data center network
Because of changing network - Programable solution is required.

Take high path functions(Data plane functions) and implement them in highly efficient hardwares/network switches. 
These are physical SDN enabled switches(Open flow switch) where data plane is implemented but control plane is moved to some centralised server.

This enables higly efficient control centre software running in Data center and push the routing data to data plane of network switches.

Here only SDN controller alone need to have network topoloy vs earlier model needs to have every router needs to have network topology to run link state algorithm.

Routing, Load balancing, Firewall can be implemented and communicated to SDN via rest based api.

Each router contains forwarding table - 
   - Match plus action abstraction : match bits in arriving packet, take action.
      - dest based forwarding - forward based on dest ip address.
This is called generalized forwarding - Any incoming traffic can be matched to any action like drop/copy/modify/log packet.
All this generalized forwarding is pushed to forwarding table by SDN remote server which programs this or configures.
Data plane blindly looks at this forwarding table and takes action.

So basically SDN helps to define many other actions apart from routing like load balancing, firewall or define any other rules etc..

********************************************************************************************************************

Network Virtualization

- In computing, Network virtulization is the process of combining hardware and software network resources and network functionality in to a single software based admin entity, a virtula network.
Virtualizes the physical network with virtual networks.

Network Function Virtualization [Virtualised Network model]
- Is the software implementing network functions like firewall, routing, load balancing that run on any underlying well known hardware or VMs. Its not bound to particular hardware.
   Traditionally each of these network functions are bound to respective particular hardware. So, One physical node per role.

VNF(Virtual Network Functions) - Implemented by software vendors who doesn't have hardware experience. These VNF run on hypervisors.


SDN and NFV are each independent technologies but they can work in tandem in Data center network.
NFV - Provisions implementaion of VNF( Firewall, Antivirus, LB etc with underlying data center hardware)
SDN - defines the path, For a give traffic what are the VNF it has to go thru.

********************************************************************************************************************

DATA CENTER NETWORK

Physical compute and storage servers are connected via switches in a huge data centre.
Servers are arranged in the form of racks and each rack has one Switch which is called Top Of Rack switch.
This switch will connect servers in this rack with others servers in different network.
So, Within data centre there is high volume of network and connectivity between each servers are needed as application are evolving from monolith to distributed and microservices.
With these modern applications more than North south traffic(client server traffic) East west traffic is more signigicant(i.e server to server). Because of microservices a client
requesting a web page has to go thru multiple servers to fetch the data and respond it back to clients.

Because of this East to West traffic SDN switches are extermely helpful for cost optimisation and speed. 
Instead of having 1000 switches we can have 10 SDN servers which can handle 1000 SDN enbabled switches which just handles data plane functionality via Openflow protocol.
SDN enabled switches are less costly compared to traditional switches.

Because of the growing demand from East to West traffic there are many challenges in DCN.

1. High volume of traffic
   causes network fault and shold provide auto recovery mechanism.
    - Number of managed objects in cloud DCN is huge because of NFVs
    - Network needs to detect dynamic VM migrations and elastic scaling of applications.
     - Boundries are blurred and its very difficult to locate and isolate issues
    connections faults, performance faults such as congestion and policy faults are some of Network faults.
Addressing network faults.
- use of self healing networks.
- Use of intelligence analysis engine to predict/detect/isolate network faults.
- Use of SDN and SDN controller for simplified cloud network operations.
- Bandwidth oversubscription.

TCP Incast
- N/w pathology that affects many to one communication pattern in datacentres.
  leads to lot of retransmission.
Its fundamentally transport layer problem and best solution can be found at TCP level

Infrastucre challenges.
- DC network cost
- DC cooling
- DC cabling


DCN evolution - 
Traditional network topology - access-aggreation-core
well suited for nort and south traffic
only layer2 network hence only need switches
easy to use and faster as there are less server to server traffic.
This can not scale for modern DC netowrk as server to server n/w huge and its causing brodcas storming
VLAN limitations - 4096 vlans
STP limitations - need more aggregation switches.

Modern DCN topologies- Clos topology
leaf-spine topology - Mesh topology
Fat tree topology

********************************************************************************************************************
Each leaf connects to each spine.
Its entirely based on IP routing layer3 network. So, Its scalable and reduntant.
Leaf and spine are of the same type. layer 3 network and uses layer 3 routing protocols.
Adding spines increases the capacity between lear nodes
Classic 3 stage clos topology
if m=n=t --- Leaf spine topology

DCN Design aspects
- Choice of topology
- Oversubscription of bandwidth
- Multipath routing - To reduce the cost and server latency
- overall cost

DCN Technology evolution
  Access-aggregate-core - Spanning Tree protocol
  Virtual Chassis Technology - Impmlement N:1 virtualisation
      Integrates the control planes of multiple devices to form a unified logical device
      challenges - scalability, reliablity, upgrad challenge, Bandwith waste

  Layer 2 multipathing technology
    popular in WAN
    The basic principle of L2MP tech is to introduce mechanisms of routing technologies used on Layer3 networks to layer 2 networks.
    Adds the addressable identifier to each device similar to IP on layer 2 
    TRILL - protocol is standardised by IETF


TRILL
- Transparent Interconnection of Lots of Links
- Is implemented by devices called TRILL switches
- Trill combines techniques from bridging and routing, and is the application of link state routing to L2 networks
- TRILL uses MAC in TRILL in MAC encapsulation
  i.e in addtion to the original etherenet header, a TRILL header that provides an addressing identifier and an outer Ethernet header
  used to forward a TRILL packet on an Ethernet network are added.
  outer MAC header - To send to next hop
  TRILL header  -  To perfrom link state routing(layer3 routing) to avoid loop
  Inner mac header - Original ethernet header

Disadvantages:
  - TRILL used VLAN IDs to identify tenants. TRILL network supports only about 4000 tenants.
  - A solution to the tenatn problem was considered at the beginning of TRILL design. A field was reserved in the TRILL header for tenant
    identification. Not used reserved field because this protocol not used or evolved further
  - Increased deployment costs : Because of specialised TRILL switches. Requires upgrad of forwarding chips.


********************************************************************************************************************
    
Overlay Network: https://info.support.huawei.com/info-finder/encyclopedia/en/Overlay+network.html
- A software defined logical network built over an existing underlay network
- Is completely decoupled from the underlay network
    - Allows the underlay network to be flexibly expanded
    - Facilitates SDN architecture deployment

NVO3 network: Network virtualisation over layer3  network
 - is a tunnel encapsulation technology that encapsulates layer 2/3 packets over tunnels(layer3)
 - NVO3 includes VXLAN.
 - VPN is one example of tunneling where it hides user's private IP address and connects to its server with over VPN.

VXLAN:
- Is the implementaion of NVO3 technology.
- It encapsulates layer2 packet in to layer3 tunnel.
- This tunneling is done by VTEPs (Edge switches or virtual switches in case of VM)
- layer2/3 packet acts as appliation data to VTEP and it doesn't care what it has. It only creates tunnel between VTEP1(at source network)
  VTEP2(destination network)
- VTEP1 encapsulates layer2/3 packet coming to it with VXLAN header and send it over layer3 network to VTEP2 and VTEP2 decapsulate it and send the underlying layer2/3 packet to actual destination.
- The VXLAN encapsulation invovles giving unique identifier to VM at VTEP1 and VM at VTEP2 whcih is called VNI(virtual network identifier)
- While encapsulating VTEP1 puts this VNI in VXLAN header, Then that is again encapsulate with UDP header(fixed udp port for vxlan), Then
  that is again encapsulated in outer IP header. Then this is again encapsulated with MAC header as it does in normal TCP/IP protocol.

Why VXLAN is better than VLAN?
- VLAN supports only 12 bits hence 4096 logical ports.
- VXLAN on the other end use 24 bits which server 16 billinon connections.
- VXLAN provides lot of flexibilty because of overlay IP network.
- Can add software defined Value added service(like firewall) easily

Control plane in DCN underlay network:
- is similar to control plane in IP network.
- Protocol used are OSPF for smaller Data center Network and BGP for large networks
- MGBGP is used by creating autonoums systems inside the data center network.

How control plane works in overlay networks.
- There are 2 widely used protocols that used in VXLAN to advertise the links.
  1. Flood and learn multicast based control plane
  2. VXLAN MPBGP EVPN control plane.

1. Flood and learn multicast based control plane
- This is done similar to the layer2 brodcasting of mac addresses.
- Ecah overlay network creates multicast group with all the VTEPs that contains atleast 1 VM which is of that VNI.
- Instead of Brodacast, It uses multicast on layer 3 network.
- VM in one VTEP will brodcast request asking for MAC address of given IP address. ARP request
- VTEPs belongs to same multicast group will get the ARP request.
- VMs in other VTEP will unicast back saying this IP address belongs to this MAC and also it puts the entry in the routing table.

2. VXLAN MPBGP EVPN control plane.
- EVPN : Ethernet Virtual private network
- Creates tunnels between each network(overlay) with underlying network.
- extension of BGP network
- Advertises its private IP addresses to other edge with in its overlay network only not to other networks.
- It avoids flooding hence used in large sized DCN networks (for more than 100 VMs)

********************************************************************************************************************
Multi DC networking

1. Single VPC can span across multiple Data centres.
2. VMs within VPC communicate at layer2
3. There are multiple uscases why we need VPC in Multiple Data centres.
    - Due to nature of applications it is hosting
    - Application or use cases served by cluster which spans across multiple DC
    - Content Delivery networks
      To provide best user experince CDN provider edge servers to host the contents along with central server
      CDN server selection strategy:
      - Based on Geographical proximity to the client via Local DNS mapping (This is static and has disadvantages)
      - Current traffic conditions 
      - IP anycast : Technique to find best/shortest path for given IP when multiple cluster having the same IP
          Routers in the internet route the client's packets to the closes cluster as determined by BGP
          CDN company assigns the same IP address to each of the clusters

Multi DC networking requirements:
1. L2 Network across DCs - VMs within VPC communicate at layer2
2. L3 networking across DCs
3. Data synchronisation and backup. Storage interconnection

1. L2 Networking across DCs
option 1: Virtual private LAN service
option 2: Use of VXLAN preferred

2. L3 networking across DCs (tunneling L3 overlay packet over L3 network)
option1 : MPLS L3VPN
option2: VXLAN based L3VPN service - Is the preferred technology


